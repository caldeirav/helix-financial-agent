# Environment Configuration for Helix Financial Agent
# Copy this file to .env and fill in your values

# ============================================================================
# HARDWARE CONFIGURATION
# ============================================================================
DEVICE=cuda
CUDA_VISIBLE_DEVICES=0

# ============================================================================
# MODEL SERVING - llama.cpp
# ============================================================================
LLAMA_CPP_BASE_URL=http://localhost:8081/v1
LLAMA_CPP_API_KEY=not-needed
AGENT_MODEL_NAME=qwen3-30b-a3b-instruct-2507

# Model parameters
AGENT_TEMPERATURE=0.7
AGENT_TOP_P=0.8
AGENT_MAX_TOKENS=4096

# ============================================================================
# SEMANTIC ROUTER - vLLM-SR
# ============================================================================
# vLLM-SR ports per documentation:
# - 8801: HTTP entry point through Envoy (OpenAI-compatible API)
# - 8889: Classification API (health, /v1/models)
# - 9190: Prometheus metrics
# - 8080: Hub UI dashboard
ROUTER_HOST=localhost
ROUTER_HTTP_PORT=8801
ROUTER_CLASSIFY_PORT=8889
ROUTER_METRICS_PORT=9190
ROUTER_ENDPOINT=http://localhost:8801/v1

# ============================================================================
# JUDGE MODEL - Gemini 2.5 Pro
# ============================================================================
# Get your API key from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-pro

# ============================================================================
# MCP SERVER CONFIGURATION
# ============================================================================
MCP_SERVER_HOST=localhost
MCP_SERVER_PORT=8000
MCP_TRANSPORT=streamable-http

# ============================================================================
# TOOL RAG CONFIGURATION
# ============================================================================
# ToolRAG (Tool Retrieval Augmented Generation) dynamically selects relevant
# tools for each query using semantic similarity search.
#
# EMBEDDING_MODEL: Model for computing query/tool embeddings
#   Default: sentence-transformers/all-MiniLM-L6-v2 (fast, good quality)
#
# TOOL_RAG_TOP_K: Max tools to retrieve from vector search
#   Note: This is initial retrieval, further filtering by threshold follows
#
# TOOL_RAG_THRESHOLD: Minimum similarity score (0.0-1.0) for tool selection
#   Lower = more tools selected (may include irrelevant)
#   Higher = fewer tools (may miss relevant ones)
#   Recommended: 0.3-0.4 for good balance
#
# TOOL_RAG_MAX_TOOLS: Maximum tools to pass to LLM (prevents context overflow)
#   Each tool adds ~1000-2000 tokens to prompt. With 16K context:
#   - max_tools=4 → ~6K tokens for tools, leaving room for query/response
#   - Without limit, 13 tools × 1500 = ~20K tokens (exceeds 16K!)
#   Set based on your model's context size.
#
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
TOOL_RAG_TOP_K=5
TOOL_RAG_THRESHOLD=0.3
TOOL_RAG_MAX_TOOLS=4

# ============================================================================
# MLFLOW TRACING
# ============================================================================
# MLflow captures end-to-end traces of agent execution including:
# - LLM calls (generator, reflector, revisor)
# - Tool executions (via MCP server)
# - Routing decisions (semantic router)
#
# Per-trace assessments are logged:
# - tool_selection_successful: Y/N
# - model_selection_successful: Y/N
# - judge_score: 0-10
#
# View traces: mlflow ui --port 5000 → http://localhost:5000
#
# Tracking URI can be:
# - Local directory: ./mlruns (default)
# - Remote server: http://mlflow-server:5000
# - Databricks: databricks://profile_name
MLFLOW_TRACKING_URI=./mlruns
MLFLOW_EXPERIMENT_NAME=helix-financial-agent

# ============================================================================
# AGENT SETTINGS
# ============================================================================
MAX_ITERATIONS=3

# ============================================================================
# DATA PATHS
# ============================================================================
DATA_DIR=./data
LOG_DIR=./logs
LOG_LEVEL=INFO

# ============================================================================
# HUGGINGFACE (for model downloads)
# ============================================================================
# HF_TOKEN is used for:
# - Downloading embedding models (sentence-transformers)
# - Accessing gated models on HuggingFace Hub
# - Higher rate limits and faster downloads
#
# Get your token from: https://huggingface.co/settings/tokens
# Without a token, you may see warnings like:
#   "Warning: You are sending unauthenticated requests to the HF Hub"
#
# The token is automatically picked up by the ToolStore when loading
# the embedding model for semantic tool selection.
#
HF_TOKEN=your_huggingface_token_here
HF_ENDPOINT=https://huggingface.co
